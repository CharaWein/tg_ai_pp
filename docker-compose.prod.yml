version: '3.8'

services:
  rag-ai-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: yourusername/rag-ai-clone:${TAG:-latest}
    container_name: rag-ai-clone-prod
    environment:
      - OLLAMA_API_URL=${OLLAMA_API_URL}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - TELEGRAM_API_ID=${TELEGRAM_API_ID}
      - TELEGRAM_API_HASH=${TELEGRAM_API_HASH}
      - TELEGRAM_PHONE=${TELEGRAM_PHONE}
      - BOT_TOKEN=${BOT_TOKEN}
      - PYTHONUNBUFFERED=1
      - DEBUG=false
      - LOG_LEVEL=INFO
    volumes:
      - rag_ai_data:/app/backend/data
      - rag_ai_logs:/app/logs
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    # Ограничиваем доступ к сети (только исходящие запросы)
    networks:
      - rag-ai-network

  # Опционально: nginx для reverse proxy если нужен веб-интерфейс
  # nginx:
  #   image: nginx:alpine
  #   ports:
  #     - "80:80"
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/nginx.conf:ro
  #   depends_on:
  #     - rag-ai-app
  #   networks:
  #     - rag-ai-network

volumes:
  rag_ai_data:
    driver: local
  rag_ai_logs:
    driver: local

networks:
  rag-ai-network:
    driver: bridge