# 0_build_vector_db_improved.py - –ò–ù–î–ï–ö–°–ò–†–û–í–ê–ù–ò–ï + LLM-–ü–ê–†–°–ò–ù–ì –§–ê–ö–¢–û–í (Mistral)

import json
import logging
import re
from pathlib import Path
from typing import List, Any, Dict
import chromadb
from chromadb.utils import embedding_functions
import requests
from config import MESSAGES_FILE, CHROMA_DB_DIR, DEBUG, OLLAMA_API_URL, OLLAMA_MODEL

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ollama config - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ config.py
OLLAMA_TIMEOUT = 600  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 10 –º–∏–Ω—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
OLLAMA_MAX_RETRIES = 3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö


class OllamaFactExtractor:
    """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Mistral 7B –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""

    @staticmethod
    def call_mistral(prompt: str, temperature: float = 0.3) -> str:
        """–í—ã–∑—ã–≤–∞–µ—Ç Mistral 7B –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ Ollama —Å retry –ª–æ–≥–∏–∫–æ–π"""
        import time
        
        for attempt in range(OLLAMA_MAX_RETRIES):
            try:
                logger.debug(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{OLLAMA_MAX_RETRIES} –≤—ã–∑–æ–≤–∞ Mistral...")
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ç–∞–π–º–∞—É—Ç–æ–≤
                max_prompt_length = 2000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø—Ä–æ–º–ø—Ç–∞
                current_prompt = prompt
                if len(current_prompt) > max_prompt_length:
                    logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({len(current_prompt)} —Å–∏–º–≤–æ–ª–æ–≤), –æ–±—Ä–µ–∑–∞—é –¥–æ {max_prompt_length}")
                    current_prompt = current_prompt[:max_prompt_length] + "..."
                
                response = requests.post(
                    f"{OLLAMA_API_URL}/api/generate",
                    json={
                        "model": OLLAMA_MODEL,
                        "prompt": current_prompt,
                        "stream": False,
                        "temperature": temperature,
                    },
                    timeout=OLLAMA_TIMEOUT,
                )
                response.raise_for_status()
                result = response.json()
                
                if "response" not in result:
                    raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Ollama: {result}")
                
                return result["response"]
                
            except requests.exceptions.Timeout:
                wait_time = (attempt + 1) * 5  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                logger.warning(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Mistral (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{OLLAMA_MAX_RETRIES}). –ñ–¥—É {wait_time} —Å–µ–∫...")
                if attempt < OLLAMA_MAX_RETRIES - 1:
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω —Ç–∞–π–º–∞—É—Ç –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
                    raise
                    
            except requests.exceptions.ConnectionError:
                logger.error("‚ùå Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞! –ó–∞–ø—É—Å—Ç–∏: ollama serve")
                raise
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 500:
                    wait_time = (attempt + 1) * 3
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ 500 –æ—Ç Ollama (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{OLLAMA_MAX_RETRIES}). –ñ–¥—É {wait_time} —Å–µ–∫...")
                    if attempt < OLLAMA_MAX_RETRIES - 1:
                        time.sleep(wait_time)
                        continue
                raise
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Mistral: {e}")
                if attempt < OLLAMA_MAX_RETRIES - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫...")
                    time.sleep(wait_time)
                    continue
                raise
        
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")

    @staticmethod
    def extract_facts(messages: List[str]) -> Dict[str, Any]:
        """
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Mistral –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤
        """
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é Mistral 7B –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–≤ —è–≤–Ω—ã–π –º—É—Å–æ—Ä
        meaningful_messages = [
            str(msg) for msg in messages
            if msg and len(str(msg).strip()) > 3
            and not re.match(r'^(–Ω–∞–π—Ç–∏|http|^\d+:\d+)', str(msg).lower())
        ][:100]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 200 –∑–Ω–∞—á–∏–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        messages_text = "\n".join(meaningful_messages)
        if not messages_text.strip():
            messages_text = "[–ù–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π]"

        logger.info(f"üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é {len(meaningful_messages)} –∑–Ω–∞—á–∏–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")

        # ===== STEP 1: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –õ–ò–ß–ù–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ò =====
        logger.info("üîç Step 1: –ò–∑–≤–ª–µ–∫–∞—é –ª–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...")
        personal_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ–∫–∏ –ª–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

{messages_text[:300]}

–í–µ—Ä–Ω–∏ JSON (—Ç–æ–ª—å–∫–æ JSON, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞):
{{
    "full_name": "–∏–º—è –∏–ª–∏ null",
    "age": "–≤–æ–∑—Ä–∞—Å—Ç –∏–ª–∏ null",
    "location": "–≥–æ—Ä–æ–¥/—Å—Ç—Ä–∞–Ω–∞ –∏–ª–∏ null",
    "timezone": "—á–∞—Å–æ–≤–æ–π –ø–æ—è—Å –∏–ª–∏ null",
    "occupation": "–ø—Ä–æ—Ñ–µ—Å—Å–∏—è –∏–ª–∏ null"
}}"""

        personal_response = OllamaFactExtractor.call_mistral(personal_prompt)
        try:
            personal_data = json.loads(personal_response)
        except json.JSONDecodeError:
            personal_data = {
                "full_name": None,
                "age": None,
                "location": None,
                "timezone": None,
                "occupation": None,
            }

        # ===== STEP 2: –ò–ù–¢–ï–†–ï–°–´ –ò –•–û–ë–ë–ò =====
        logger.info("üéÆ Step 2: –ò–∑–≤–ª–µ–∫–∞—é –∏–Ω—Ç–µ—Ä–µ—Å—ã –∏ —Ö–æ–±–±–∏...")
        hobbies_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –Ω–∞–π–¥–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã:

{messages_text[:300]}

–í–µ—Ä–Ω–∏ JSON (—Ç–æ–ª—å–∫–æ JSON):
{{
    "games": ["—Å–ø–∏—Å–æ–∫ –∏–≥—Ä –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è"],
    "music": ["–∂–∞–Ω—Ä—ã –º—É–∑—ã–∫–∏ –∏–ª–∏ –∞—Ä—Ç–∏—Å—Ç—ã"],
    "programming": true/false –µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å –∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é,
    "sports": ["–≤–∏–¥—ã —Å–ø–æ—Ä—Ç–∞"],
    "other_interests": ["–¥—Ä—É–≥–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã"]
}}"""

        hobbies_response = OllamaFactExtractor.call_mistral(hobbies_prompt)
        try:
            hobbies_data = json.loads(hobbies_response)
        except json.JSONDecodeError:
            hobbies_data = {
                "games": [],
                "music": [],
                "programming": False,
                "sports": [],
                "other_interests": [],
            }

        # ===== STEP 3: –£–ë–ï–ñ–î–ï–ù–ò–Ø –ò –¶–ï–ù–ù–û–°–¢–ò =====
        logger.info("üéØ Step 3: –ò–∑–≤–ª–µ–∫–∞—é —É–±–µ–∂–¥–µ–Ω–∏—è –∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏...")
        beliefs_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ —É–±–µ–∂–¥–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞:

{messages_text[:300]}

–í–µ—Ä–Ω–∏ JSON (—Ç–æ–ª—å–∫–æ JSON):
{{
    "core_values": ["–æ—Å–Ω–æ–≤–Ω—ã–µ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ–∫–∞"],
    "life_philosophy": "–æ–±—â–∞—è —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è –∏–ª–∏ null",
    "important_beliefs": ["–≤–∞–∂–Ω—ã–µ —É–±–µ–∂–¥–µ–Ω–∏—è"]
}}"""

        beliefs_response = OllamaFactExtractor.call_mistral(beliefs_prompt)
        try:
            beliefs_data = json.loads(beliefs_response)
        except json.JSONDecodeError:
            beliefs_data = {
                "core_values": [],
                "life_philosophy": None,
                "important_beliefs": [],
            }

        # ===== STEP 4: –°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø =====
        logger.info("üí¨ Step 4: –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è...")
        style_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –≤ —ç—Ç–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö:

{messages_text[:800]}

–í–µ—Ä–Ω–∏ JSON (—Ç–æ–ª—å–∫–æ JSON):
{{
    "tone": "—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π/–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π/—Å–º–µ—à–∞–Ω–Ω—ã–π",
    "personality_traits": ["—á–µ—Ä—Ç—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞"],
    "communication_style": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª—è",
    "keyword_style": ["—á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã"]
}}"""

        style_response = OllamaFactExtractor.call_mistral(style_prompt)
        try:
            style_data = json.loads(style_response)
        except json.JSONDecodeError:
            style_data = {
                "tone": "unknown",
                "personality_traits": [],
                "communication_style": "unknown",
                "keyword_style": [],
            }

        # ===== STEP 5: –û–ë–†–ê–ó–û–í–ê–ù–ò–ï –ò –ù–ê–í–´–ö–ò =====
        logger.info("üíª Step 5: –ò–∑–≤–ª–µ–∫–∞—é –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –Ω–∞–≤—ã–∫–∏...")
        skills_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –Ω–∞–≤—ã–∫–∏:

{messages_text[:300]}

–í–µ—Ä–Ω–∏ JSON (—Ç–æ–ª—å–∫–æ JSON):
{{
    "languages": ["—è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è"],
    "skills": ["–Ω–∞–≤—ã–∫–∏ –∏ —É–º–µ–Ω–∏—è"],
    "education_level": "—É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–ª–∏ null",
    "specialization": "–æ–±–ª–∞—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ null"
}}"""

        skills_response = OllamaFactExtractor.call_mistral(skills_prompt)
        try:
            skills_data = json.loads(skills_response)
        except json.JSONDecodeError:
            skills_data = {
                "languages": [],
                "skills": [],
                "education_level": None,
                "specialization": None,
            }

        # ===== –°–ë–û–†–ö–ê –ò–¢–û–ì–û–í–û–ì–û JSON =====
        facts = {
            "personal": {
                "full_name": personal_data.get("full_name"),
                "age": personal_data.get("age"),
                "location": personal_data.get("location"),
                "timezone": personal_data.get("timezone"),
                "occupation": personal_data.get("occupation"),
            },
            "location": {
                "current_city": personal_data.get("location"),
            },
            "education": {
                "education_level": skills_data.get("education_level"),
                "specialization": skills_data.get("specialization"),
            },
            "hobbies": {
                "games": hobbies_data.get("games", []),
                "music": hobbies_data.get("music", []),
                "programming": hobbies_data.get("programming", False),
                "sports": hobbies_data.get("sports", []),
                "likes": hobbies_data.get("other_interests", []),
            },
            "skills": {
                "languages": skills_data.get("languages", []),
                "skills": skills_data.get("skills", []),
            },
            "beliefs": {
                "core_values": beliefs_data.get("core_values", []),
                "life_philosophy": beliefs_data.get("life_philosophy"),
                "core_beliefs": beliefs_data.get("important_beliefs", []),
            },
            "communication": {
                "tone": style_data.get("tone", "unknown"),
                "personality_traits": style_data.get("personality_traits", []),
                "style": style_data.get("communication_style", "unknown"),
                "keyword_style": style_data.get("keyword_style", []),
            },
            "raw_messages": meaningful_messages[:50],
            "extraction_method": "Mistral 7B (Ollama)",
        }

        # ===== –õ–û–ì–ò–†–û–í–ê–ù–ò–ï =====
        logger.info("\n‚úÖ –ò–ó–í–õ–ï–ß–ï–ù–û:")
        logger.info(f"  üë§ –ò–º—è: {facts['personal']['full_name']}")
        logger.info(f"  üìç –õ–æ–∫–∞—Ü–∏—è: {facts['personal']['location']}")
        logger.info(f"  üéÆ –ò–≥—Ä: {len(facts['hobbies']['games'])}")
        logger.info(f"  üéµ –ú—É–∑—ã–∫–∏: {len(facts['hobbies']['music'])}")
        logger.info(f"  üíª –ù–∞–≤—ã–∫–æ–≤: {len(facts['skills']['skills'])}")
        logger.info(f"  üìä –Ø–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: {len(facts['skills']['languages'])}")
        logger.info(f"  ‚úä –¶–µ–Ω–Ω–æ—Å—Ç–µ–π: {len(facts['beliefs']['core_values'])}")
        logger.info(f"  üí¨ –ß–µ—Ä—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞: {len(facts['communication']['personality_traits'])}")

        return facts


class MessageProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ—á–∏—Å—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""

    @staticmethod
    def clean_text(text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞"""
        if not isinstance(text, str):
            text = str(text)
        text = re.sub(r"\s+", " ", text).strip()
        return text

    @staticmethod
    def is_valid_message(message: Any) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –º—É—Å–æ—Ä–Ω–æ–µ"""
        if message is None:
            return False
        text = str(message).strip()
        if len(text) < 3:
            return False

        garbage_patterns = [
            r"^\s*$",
            r"^null$",
            r"^undefined$",
            r"^\[DELETED\]$",
            r"^\.\.\.$",
            r"^\[.*\]$",
            r"^[0-9:.\-\s]+$",
            r"^(ok|–æ–∫|–¥–∞|–Ω–µ—Ç|yes|no|–ø–∂–ª—Å—Ç|–ø–ª–∑)$",
        ]

        for pattern in garbage_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                return False
        return True

    @staticmethod
    def extract_metadata(message: Any) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        if isinstance(message, dict):
            cleaned_msg = message.copy()
            for key, value in cleaned_msg.items():
                if isinstance(value, str):
                    cleaned_msg[key] = MessageProcessor.clean_text(value)
            return cleaned_msg
        else:
            cleaned_text = MessageProcessor.clean_text(message)
            return {
                "text": cleaned_text,
                "type": "text",
                "cleaned": True,
            }

    @staticmethod
    def prepare_messages(messages: List[Any]) -> tuple:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        valid_messages = []
        valid_texts = []
        valid_metadatas = []
        stats = {
            "total": len(messages),
            "valid": 0,
            "invalid": 0,
            "invalid_reasons": {},
        }

        for i, msg in enumerate(messages):
            if not MessageProcessor.is_valid_message(msg):
                stats["invalid"] += 1
                reason = "too_short" if len(str(msg).strip()) < 3 else "garbage_pattern"
                stats["invalid_reasons"][reason] = (
                    stats["invalid_reasons"].get(reason, 0) + 1
                )
                continue

            cleaned_message = MessageProcessor.extract_metadata(msg)

            if isinstance(cleaned_message, dict) and "text" in cleaned_message:
                text_for_vector = cleaned_message["text"]
            elif isinstance(cleaned_message, dict):
                text_for_vector = json.dumps(cleaned_message, ensure_ascii=False)
            else:
                text_for_vector = str(cleaned_message)

            vector_metadata = {
                "original_index": i,
                "message_length": len(text_for_vector),
                "processed": True,
            }

            valid_messages.append(cleaned_message)
            valid_texts.append(text_for_vector)
            valid_metadatas.append(vector_metadata)
            stats["valid"] += 1

        return valid_messages, valid_texts, valid_metadatas, stats


def build_vector_db():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç ChromaDB –±–∞–∑—É —Å LLM-–ø–∞—Ä—Å–∏–Ω–≥–æ–º —Ñ–∞–∫—Ç–æ–≤"""
    logger.info("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é messages...")

    if not Path(MESSAGES_FILE).exists():
        logger.error(f"‚ùå {MESSAGES_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        logger.info("üí° –°–æ–≤–µ—Ç: –£–±–µ–¥–∏—Å—å —á—Ç–æ —Ç—ã —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª user_messages.json –≤ data/")
        return False

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        with open(MESSAGES_FILE, "r", encoding="utf-8") as f:
            messages = json.load(f)

        if isinstance(messages, dict):
            messages = [msg for msgs in messages.values() for msg in msgs]

        if not messages:
            logger.warning("‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ñ–∞–π–ª–µ")
            return False

        logger.info(f"üìù –ù–∞–π–¥–µ–Ω–æ {len(messages)} —Å—ã—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ –æ—á–∏—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        processor = MessageProcessor()
        cleaned_messages, texts, metadatas, stats = processor.prepare_messages(
            messages
        )

        logger.info(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ß–ò–°–¢–ö–ò:")
        logger.info(f" ‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['valid']}")
        logger.info(f" üóëÔ∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {stats['invalid']}")
        if stats["invalid_reasons"]:
            for reason, count in stats["invalid_reasons"].items():
                logger.info(f" ‚Ä¢ {reason}: {count}")

        # ===== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –§–ê–ö–¢–û–í –° MISTRAL =====
        logger.info("\nüìå –ò–ó–í–õ–ï–ö–ê–Æ –§–ê–ö–¢–´ –° –ü–û–ú–û–©–¨–Æ MISTRAL 7B...")
        extractor = OllamaFactExtractor()
        facts = extractor.extract_facts(texts if texts else messages)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–∫—Ç—ã
        facts_path = Path(MESSAGES_FILE).parent / "facts_advanced.json"
        with open(facts_path, "w", encoding="utf-8") as f:
            json.dump(facts, f, ensure_ascii=False, indent=2)
        logger.info(f"\nüíæ –§–∞–∫—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {facts_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        cleaned_messages_path = Path(MESSAGES_FILE).parent / "cleaned_messages.json"
        with open(cleaned_messages_path, "w", encoding="utf-8") as f:
            json.dump(cleaned_messages, f, ensure_ascii=False, indent=2)
        logger.info(f"üíæ –û—á–∏—â–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {cleaned_messages_path}")

        # –°–æ–∑–¥–∞–µ–º ChromaDB
        client = chromadb.PersistentClient(path=str(CHROMA_DB_DIR))

        try:
            client.delete_collection(name="user_messages")
            logger.info("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è")
        except Exception as e:
            logger.debug(f"‚ÑπÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∞: {e}")

        embedding_function = (
            embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name="paraphrase-multilingual-MiniLM-L12-v2"
            )
        )

        collection = client.create_collection(
            name="user_messages", embedding_function=embedding_function
        )

        if texts:
            logger.info(f"üìä –ò–Ω–¥–µ–∫—Å–∏—Ä—É—é {len(texts)} –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

            BATCH_SIZE = 1000
            ids = [f"msg_{i}" for i in range(len(texts))]
            total_batches = (len(texts) + BATCH_SIZE - 1) // BATCH_SIZE
            logger.info(
                f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {total_batches} –±–∞—Ç—á–µ–π –ø–æ {BATCH_SIZE} —Å–æ–æ–±—â–µ–Ω–∏–π..."
            )

            for batch_num in range(total_batches):
                start_idx = batch_num * BATCH_SIZE
                end_idx = min((batch_num + 1) * BATCH_SIZE, len(texts))
                batch_ids = ids[start_idx:end_idx]
                batch_texts = texts[start_idx:end_idx]
                batch_metadatas = metadatas[start_idx:end_idx]

                collection.add(
                    ids=batch_ids,
                    documents=batch_texts,
                    metadatas=batch_metadatas,
                )

                if (batch_num + 1) % 10 == 0 or (batch_num + 1) == total_batches:
                    logger.info(
                        f"‚úÖ –ë–∞—Ç—á {batch_num + 1}/{total_batches} –æ–±—Ä–∞–±–æ—Ç–∞–Ω ({end_idx - start_idx} —Å–æ–æ–±—â–µ–Ω–∏–π)"
                    )

        logger.info(f"\n‚úÖ ChromaDB collection —Å–æ–∑–¥–∞–Ω–∞!")
        logger.info(f" üìÅ –ü—É—Ç—å: {CHROMA_DB_DIR}")
        logger.info(f" üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(texts)}")
        logger.info(f" üíæ JSON —Ñ–∞–∫—Ç—ã: {facts_path}")
        logger.info(f" üíæ JSON —Å–æ–æ–±—â–µ–Ω–∏—è: {cleaned_messages_path}")
        if stats["total"] > 0:
            logger.info(
                f" üéØ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {stats['valid']}/{stats['total']} ({stats['valid']/stats['total']*100:.1f}%)"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –±–∞–∑–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç
        try:
            if texts:
                test_count = collection.count()
                logger.info(f" ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞: –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {test_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

                results = collection.query(query_texts=["—Ç–µ—Å—Ç"], n_results=2)
                logger.info(
                    f" üîé –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫: –Ω–∞–π–¥–µ–Ω–æ {len(results['documents'][0])} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
                )
            else:
                logger.info(f" ‚ÑπÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è –ø—É—Å—Ç–∞ (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π)")
        except Exception as e:
            logger.warning(f" ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é: {e}")

        return True

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        if DEBUG:
            import traceback

            logger.error(f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    success = build_vector_db()
    exit(0 if success else 1)
