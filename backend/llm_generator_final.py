# llm_generator_final_FIXED.py - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç

import requests
import json
import chromadb
import logging
from datetime import datetime
from chromadb.utils import embedding_functions
from config import OLLAMA_API_URL, OLLAMA_MODEL, CHROMA_DB_DIR

logger = logging.getLogger(__name__)


def load_prompt_template():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç prompt_template.json –Ω–∞–ø—Ä—è–º—É—é"""
    try:
        with open('data/prompt_template.json', 'r', encoding='utf-8') as f:
            template = json.load(f)
            return template
    except FileNotFoundError:
        logger.error("‚ùå data/prompt_template.json –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None


class DialogueHistory:
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞"""
    
    def __init__(self, max_history=5):
        self.max_history = max_history
        self.history_file = 'data/dialogue_history.json'
        self.history = self.load_history()
    
    def load_history(self):
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return []
    
    def save_history(self):
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, ensure_ascii=False, indent=2)
    
    def add_message(self, role, text, chat_id=None):
        msg = {
            "role": role,
            "text": text,
            "timestamp": datetime.now().isoformat(),
            "chat_id": chat_id
        }
        self.history.append(msg)
        if len(self.history) > self.max_history * 2:
            self.history = self.history[-self.max_history * 2:]
        self.save_history()
    
    def clear_chat_history(self, chat_id):
        self.history = [msg for msg in self.history if msg.get('chat_id') != chat_id]
        self.save_history()


class LLMGenerator:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã - –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    
    def __init__(self):
        self.collection = None
        
        try:
            self.client = chromadb.PersistentClient(path=CHROMA_DB_DIR)
            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name="paraphrase-multilingual-MiniLM-L12-v2"
            )
            self.collection = self.client.get_collection(
                name="user_messages",
                embedding_function=self.embedding_function
            )
            logger.info(f"‚úÖ ChromaDB –∑–∞–≥—Ä—É–∂–µ–Ω")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ChromaDB –æ—à–∏–±–∫–∞: {e}")
        
        self.history = DialogueHistory(max_history=5)
        self.prompt_template = load_prompt_template()
        
        if not self.prompt_template:
            logger.error("‚ùå Prompt template –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            raise RuntimeError("–ó–∞–ø—É—Å—Ç–∏ prompt_generator_advanced.py")
        
        # –¢–û–õ–¨–ö–û –æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω—ã–µ —É—Ç–µ—á–∫–∏ –ø—Ä–æ–º—Ç–∞
        self.bad_patterns = [
            '—è –Ω–µ —á–µ–ª–æ–≤–µ–∫',
            '—è –ø–æ–º–æ—â–Ω–∏–∫ claude',
            '—è –ø–æ–º–æ—â–Ω–∏–∫ –æ—Ç anthropic',
            '—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç openai',
            '—è —è–∑—ã–∫ –º–æ–¥–µ–ª—å',
            '—Å–ª–µ–¥—É–π —ç—Ç–∏–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º',
            '[–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è',
            '[—Å–∏—Å—Ç–µ–º–∞',
            '[–ø—Ä–æ–º—Ç',
        ]
        
        # –ú–∞—Ä–∫–µ—Ä—ã –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
        self.example_markers = [
            '–Ω–∞–ø—Ä–∏–º–µ—Ä:', '–Ω–∞–ø—Ä–∏–º–µ—Ä -', '–ø—Ä–∏–º–µ—Ä—ã:',
            '* –ø—Ä—è–º–æ–π,', '* –æ—Ç–≤–µ—á–∞—é', '* –Ω–µ –Ω–∞—Ä—É—à–∏–ª',
            '- "–ø—Ä–∏–≤–µ—Ç!', '- "–∫–∞–∫ –¥–µ–ª–∞',
            '–æ—Ç–≤–µ—á–∞—é –∫–æ—Ä–æ—Ç–∫–æ', '–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª',
        ]
    
    def clean_answer(self, answer):
        """–§–ò–ù–ê–õ–¨–ù–ê–Ø —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è"""
        if not answer:
            return ""
        
        answer = answer.strip()
        answer_lower = answer.lower()
        
        # –£–¢–ï–ß–ö–ò –ü–†–û–ú–¢–ê
        for bad in self.bad_patterns:
            if bad in answer_lower:
                logger.warning(f"‚ö†Ô∏è –£—Ç–µ—á–∫–∞ –ø—Ä–æ–º—Ç–∞: {bad}")
                return ""
        
        # –ü–†–ò–ú–ï–†–´ –ò–ó –ü–†–û–ú–¢–ê - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –î–û –ø—Ä–∏–º–µ—Ä–æ–≤
        for marker in self.example_markers:
            if marker in answer_lower:
                # –ë–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –î–û –º–∞—Ä–∫–µ—Ä–∞
                parts = answer_lower.split(marker)
                answer = answer[:len(answer_lower) - len(parts[-1])].strip()
                logger.info(f"üî™ –û–±—Ä–µ–∑–∞–ª –ø—Ä–∏–º–µ—Ä—ã –ø–æ—Å–ª–µ: '{marker}'")
                break
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        bad_markers = ['–ò–°–¢–û–†–ò–Ø:', '[–í–æ–ø—Ä–æ—Å:]', '[–û—Ç–≤–µ—Ç]:', '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:']
        for marker in bad_markers:
            if marker in answer:
                answer = answer.split(marker)[0].strip()
        
        # –£–¥–∞–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã-–∑–≤–µ–∑–¥–æ—á–∫–∏ (*) –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        lines = answer.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if line.startswith('* ') or line.startswith('- '):
                # –≠—Ç–æ –ø—Ä–∏–º–µ—Ä - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue
            if line:
                cleaned_lines.append(line)
        
        answer = '\n'.join(cleaned_lines).strip()
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü –µ—Å–ª–∏ –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        paragraphs = answer.split('\n\n')
        if len(paragraphs) > 2 and len(answer) > 600:
            answer = paragraphs[0].strip()
        
        answer = answer.strip()
        
        # –í–ê–õ–ò–î–ê–¶–ò–Ø
        if len(answer) < 3:
            logger.warning(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return ""
        
        if len(answer) > 1000:
            # –û–±—Ä–µ–∑–∞–µ–º –Ω–∞ —Ç–æ—á–∫–µ
            answer = answer[:1000]
            last_period = answer.rfind('.')
            if last_period > 500:
                answer = answer[:last_period + 1]
        
        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç —á–∏—Å—Ç—ã–π ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤)")
        return answer
    
    def generate_answer(self, question, chat_id=None):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç"""
        
        logger.info(f"\nüöÄ generate_answer: {question[:50]}")
        logger.info(f"üìù URL: {OLLAMA_API_URL}/api/chat")
        logger.info(f"üìù Model: {OLLAMA_MODEL}")
        
        # –ü–æ–ª—É—á–∞–µ–º system prompt –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ template
        system_prompt = self.prompt_template.get('system_prompt', '')
        if not system_prompt:
            logger.error("‚ùå system_prompt –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ template!")
            return None
        
        data = {
            "model": OLLAMA_MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            "stream": False,
            "temperature": 0.7,
            "top_p": 0.85
        }
        
        try:
            resp = requests.post(
                f"{OLLAMA_API_URL}/api/chat",
                json=data,
                timeout=30
            )
            
            logger.info(f"üìä Status: {resp.status_code}")
            
            if resp.status_code == 200:
                result = resp.json()
                answer = result.get('message', {}).get('content', '').strip()
                
                logger.info(f"üì• –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {len(answer)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                answer = self.clean_answer(answer)
                
                if answer:
                    logger.info(f"‚ú® –§–∏–Ω–∞–ª: {len(answer)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return answer
                else:
                    logger.warning(f"‚ùå –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω")
                    return None
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ {resp.status_code}")
                return None
        
        except Exception as e:
            logger.error(f"‚ùå {e}")
            return None
    
    def generate_final_answer(self, question, chat_id=None):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
        
        for attempt in range(2):
            logger.info(f"\n{'='*60}")
            logger.info(f"‚è±Ô∏è  –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/2")
            logger.info(f"{'='*60}")
            
            answer = self.generate_answer(question, chat_id)
            
            if answer:
                if chat_id:
                    self.history.add_message("user", question, chat_id)
                    self.history.add_message("assistant", answer, chat_id)
                
                return answer
            
            logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/2 –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞")
        
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å–ª–µ 2 –ø–æ–ø—ã—Ç–æ–∫")
        return ""


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
generator = LLMGenerator()


def get_answer(question, chat_id=None, use_history=True):
    return generator.generate_final_answer(question, chat_id)


def clear_history(chat_id):
    generator.history.clear_chat_history(chat_id)
