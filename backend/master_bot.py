# master_bot.py
import os
import logging
import json
import asyncio
import time
from typing import List, Dict, Any
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import sys

sys.path.append(os.path.dirname(__file__))

load_dotenv()

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

class OpenLlamaTrainer:
    """–¢—Ä–µ–Ω–µ—Ä –¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Å—Ç–∏–ª–µ Llama"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.available_models = [
            "microsoft/DialoGPT-medium",  # –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —á–∞—Ç–æ–≤
            "microsoft/DialoGPT-large",   # –ë–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
            "facebook/blenderbot-400M-distill",  # –•–æ—Ä–æ—à–∞—è –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
            "IlyaGusev/fred-t5-ru-turbo",  # –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è
            "ai-forever/rugpt3large_based_on_gpt2"  # –†—É—Å—Å–∫–∞—è GPT
        ]
        
    def load_model(self, model_index: int = 0):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞"""
        try:
            import torch
            from transformers import AutoTokenizer, AutoModelForCausalLM
            
            model_name = self.available_models[model_index]
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_name}")
            
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
                trust_remote_code=True
            )
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {self.available_models[model_index]}: {e}")
            
            # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
            if model_index + 1 < len(self.available_models):
                logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å: {self.available_models[model_index + 1]}")
                return self.load_model(model_index + 1)
            else:
                logger.error("‚ùå –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
                return False
    
    def prepare_training_data(self, training_data: List[Dict]) -> List[Dict]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        formatted_data = []
        
        for item in training_data:
            if not item.get('text') or len(item['text'].strip()) < 10:
                continue
                
            text = item['text'].strip()
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            if "dialo" in self.tokenizer.name_or_path.lower() or "blender" in self.tokenizer.name_or_path.lower():
                # –î–ª—è –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
                formatted_text = f"User: {text}\nBot:"
            elif "gpt" in self.tokenizer.name_or_path.lower():
                # –î–ª—è GPT-—Å—Ç–∏–ª—è –º–æ–¥–µ–ª–µ–π
                formatted_text = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {text}\n–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:"
            else:
                # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                formatted_text = text
            
            encoded = self.tokenizer(
                formatted_text,
                truncation=True,
                max_length=256,  # –£–∫–æ—Ä–æ—Ç–∏–ª–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                padding=False,
                return_tensors=None
            )
            
            formatted_data.append({
                "input_ids": encoded["input_ids"],
                "attention_mask": encoded["attention_mask"],
                "labels": encoded["input_ids"].copy()
            })
        
        return formatted_data
    
    def train_model(self, user_id: str, training_data: List[Dict]) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        try:
            import torch
            from peft import LoraConfig, get_peft_model, TaskType
            from transformers import TrainingArguments, Trainer
            
            start_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
            if len(training_data) < 3:
                return {
                    "success": False,
                    "message": f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(training_data)} —Å–æ–æ–±—â–µ–Ω–∏–π (—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3)",
                    "training_time": 0,
                    "samples_used": 0
                }
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
            if self.model is None:
                if not self.load_model():
                    return {
                        "success": False,
                        "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å",
                        "training_time": 0,
                        "samples_used": 0
                    }
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            formatted_data = self.prepare_training_data(training_data)
            if not formatted_data:
                return {
                    "success": False,
                    "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
                    "training_time": 0,
                    "samples_used": 0
                }
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º LoRA –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
            try:
                lora_config = LoraConfig(
                    task_type=TaskType.CAUSAL_LM,
                    inference_mode=False,
                    r=8,
                    lora_alpha=32,
                    lora_dropout=0.1,
                    target_modules=["q_proj", "v_proj", "k_proj", "o_proj", "c_proj"]
                )
                model = get_peft_model(self.model, lora_config)
                use_lora = True
            except:
                model = self.model
                use_lora = False
                logger.info("‚ö†Ô∏è LoRA –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
            training_args = TrainingArguments(
                output_dir=f"trained_models/user_{user_id}",
                overwrite_output_dir=True,
                num_train_epochs=2,
                per_device_train_batch_size=1,
                gradient_accumulation_steps=4,
                warmup_steps=20,
                logging_steps=5,
                save_steps=50,
                learning_rate=1e-4,
                fp16=torch.cuda.is_available(),
                optim="adamw_torch",
                remove_unused_columns=False,
                dataloader_pin_memory=False,
            )
            
            # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
            trainer = Trainer(
                model=model,
                args=training_args,
                train_dataset=formatted_data,
                tokenizer=self.tokenizer,
            )
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(formatted_data)} –ø—Ä–∏–º–µ—Ä–∞—Ö...")
            trainer.train()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            trainer.save_model()
            self.tokenizer.save_pretrained(f"trained_models/user_{user_id}")
            
            training_time = time.time() - start_time
            
            method = "LoRA" if use_lora else "Full"
            
            return {
                "success": True,
                "message": f"–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –Ω–∞ {len(formatted_data)} –ø—Ä–∏–º–µ—Ä–∞—Ö ({method})",
                "model_path": f"trained_models/user_{user_id}",
                "training_time": round(training_time, 2),
                "samples_used": len(formatted_data),
                "method": method
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return {
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}",
                "training_time": 0,
                "samples_used": 0
            }

class MasterBot:
    def __init__(self):
        self.bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.training_status = {}
        
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
        welcome_text = """
ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Open AI Clone Creator!

–Ø —Å–æ–∑–¥–∞—é –≤–∞—à—É —Ç–æ—á–Ω—É—é AI-–∫–æ–ø–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π.

üöÄ **–û–¢–ö–†–´–¢–ê–Ø –í–ï–†–°–ò–Ø:**
- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª—è—Ö (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç—É–ø–∞)
- –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è LoRA –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏  
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ

**–ö–æ–º–∞–Ω–¥—ã:**
/collect_data - üì• –°–æ–±—Ä–∞—Ç—å –º–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram
/train_ai - üß† –û–±—É—á–∏—Ç—å AI-–∫–ª–æ–Ω (5-15 –º–∏–Ω)
/get_link - üîó –ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –≤–µ–±-—á–∞—Ç
/status - üìä –°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è

**–ü—Ä–æ—Ü–µ—Å—Å:**
1. –°–±–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π (2-5 –º–∏–Ω—É—Ç)
2. –û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
3. –ë—ã—Å—Ç—Ä–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ (5-15 –º–∏–Ω—É—Ç) 
4. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

–ù–∞—á–Ω–∏—Ç–µ —Å /collect_data
        """
        await update.message.reply_text(welcome_text)

    async def collect_data_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        user_id = str(update.effective_user.id)
        user_name = update.effective_user.first_name
        
        progress_msg = await update.message.reply_text(
            "üì• –ó–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä –≤–∞—à–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...\n"
            "‚è≥ –≠—Ç–æ –∑–∞–π–º–µ—Ç 2-5 –º–∏–Ω—É—Ç...\n\n"
            "üîç –°–∫–∞–Ω–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥–∏...\n"
            "üìù –°–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è...\n"
            "üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ..."
        )
        
        try:
            from data_collector import TelegramDataCollector
            collector = TelegramDataCollector(user_id)
            result = await collector.collect_and_save()
            
            if not result.get('success'):
                error_msg = result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')
                await progress_msg.edit_text(
                    f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:\n{error_msg}\n\n"
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram API –≤ .env —Ñ–∞–π–ª–µ."
                )
                return
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            message_count = result['message_count']
            cleaned_count = result.get('cleaned_count', message_count)
            
            quality_indicator = "üëç" if cleaned_count > 10 else "üëé" if cleaned_count > 3 else "‚ùå"
            
            await progress_msg.edit_text(
                f"‚úÖ –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω, {user_name}!\n\n"
                f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n"
                f"‚Ä¢ –°–æ–±—Ä–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {message_count}\n"
                f"‚Ä¢ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {cleaned_count}\n"
                f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {quality_indicator}\n\n"
                f"{'üéØ –û—Ç–ª–∏—á–Ω–æ! –ú–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å AI-–∫–ª–æ–Ω!' if cleaned_count > 10 else '‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å' if cleaned_count > 3 else '‚ùå –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è'}\n\n"
                f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ /train_ai —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ."
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            await progress_msg.edit_text(
                f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö:\n{str(e)}\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
            )

    async def train_ai_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–∏"""
        user_id = str(update.effective_user.id)
        user_name = update.effective_user.first_name
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
        model_path = f"trained_models/user_{user_id}"
        if os.path.exists(model_path):
            await update.message.reply_text(
                "‚úÖ –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω—ã–π AI-–∫–ª–æ–Ω!\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /get_link –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–∫–∏.\n\n"
                "–î–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è —É–¥–∞–ª–∏—Ç–µ –ø–∞–ø–∫—É:\n"
                f"`trained_models/user_{user_id}`"
            )
            return

        progress_msg = await update.message.reply_text(
            "üß† –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–∏...\n"
            "‚è≥ –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 5-15 –º–∏–Ω—É—Ç\n\n"
            "üéØ –≠—Ç–∞–ø—ã –æ–±—É—á–µ–Ω–∏—è:\n"
            "1. –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏...\n"
            "2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–¥–∞–ø—Ç–µ—Ä–∞...\n" 
            "3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n"
            "4. –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ...\n"
            "5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏..."
        )
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            data_file = f"user_data/{user_id}/training_data.json"
            if not os.path.exists(data_file):
                await progress_msg.edit_text("‚ùå –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                return
            
            with open(data_file, 'r', encoding='utf-8') as f:
                user_messages = json.load(f)
            
            await progress_msg.edit_text(
                f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(user_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π\n"
                "üîç –ò—â–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å...\n"
                "‚ö° –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\n"
                "üß† –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ..."
            )
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Open —Ç—Ä–µ–Ω–µ—Ä
            trainer = OpenLlamaTrainer()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            def train_wrapper():
                return trainer.train_model(user_id, user_messages)
            
            loop = asyncio.get_event_loop()
            training_results = await loop.run_in_executor(None, train_wrapper)
            
            if not training_results["success"]:
                await progress_msg.edit_text(
                    f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:\n{training_results['message']}\n\n"
                    f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö /collect_data"
                )
                return
            
            # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –¥–ª—è –¥–æ—Å—Ç—É–ø–∞
            share_service = self.get_share_service()
            clone_name = f"AI –ö–ª–æ–Ω {user_name}"
            token = share_service.generate_share_link(user_id, clone_name)
            web_url = f"http://localhost:8001/clone/{token}/web"
            
            total_minutes = training_results['training_time'] / 60
            
            await progress_msg.edit_text(
                f"üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û, {user_name}!\n\n"
                f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {total_minutes:.1f} –º–∏–Ω—É—Ç\n"
                f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n"
                f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π: {len(user_messages)}\n"
                f"‚Ä¢ –û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {training_results['samples_used']}\n"
                f"‚Ä¢ –ú–µ—Ç–æ–¥: {training_results.get('method', 'Standard')}\n\n"
                f"üåê –í–∞—à–∞ —Å—Å—ã–ª–∫–∞ –¥–ª—è —á–∞—Ç–∞:\n{web_url}\n\n"
                f"üí° –ü–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–µ —á—Ç–æ–±—ã –ø–æ–æ–±—â–∞—Ç—å—Å—è —Å –≤–∞—à–∏–º AI-–∫–ª–æ–Ω–æ–º!"
            )
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏:\n{str(e)}\n\n"
                f"–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                f"‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö (< 3 —Å–æ–æ–±—â–µ–Ω–∏–π)\n"
                f"‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é\n"
                f"‚Ä¢ –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                f"1. –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö /collect_data\n"
                f"2. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞\n"
                f"3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ"
            )

    async def get_link_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∫–ª–æ–Ω"""
        user_id = str(update.effective_user.id)
        user_name = update.effective_user.first_name
        
        try:
            share_service = self.get_share_service()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
            model_path = f"trained_models/user_{user_id}"
            
            if not os.path.exists(model_path):
                await update.message.reply_text(
                    "‚ùå –£ –≤–∞—Å –µ—â–µ –Ω–µ—Ç –æ–±—É—á–µ–Ω–Ω–æ–≥–æ AI-–∫–ª–æ–Ω–∞.\n\n"
                    "–°–Ω–∞—á–∞–ª–∞:\n"
                    "1. –°–æ–±–µ—Ä–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ /collect_data\n" 
                    "2. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å /train_ai\n\n"
                    "–û–±—É—á–µ–Ω–∏–µ –∑–∞–π–º–µ—Ç 5-15 –º–∏–Ω—É—Ç ‚ö°"
                )
                return
            
            # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∞–∫—Ç–∏–≤–Ω—É—é —Å—Å—ã–ª–∫—É
            existing_links = share_service.get_all_links()
            user_link = None
            
            for token, info in existing_links.items():
                if info.get('user_id') == user_id and info.get('active', True):
                    user_link = f"http://localhost:8001/clone/{token}/web"
                    break
            
            if user_link:
                await update.message.reply_text(
                    f"üîó –í–∞—à AI-–∫–ª–æ–Ω –≥–æ—Ç–æ–≤, {user_name}!\n\n"
                    f"{user_link}\n\n"
                    f"üí° –ü–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–µ —á—Ç–æ–±—ã –ø–æ–æ–±—â–∞—Ç—å—Å—è —Å –≤–∞—à–µ–π AI-–∫–æ–ø–∏–µ–π!"
                )
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Å—ã–ª–∫—É
                clone_name = f"AI –ö–ª–æ–Ω {user_name}"
                token = share_service.generate_share_link(user_id, clone_name)
                user_link = f"http://localhost:8001/clone/{token}/web"
                
                await update.message.reply_text(
                    f"üîó –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Å—Å—ã–ª–∫–∞, {user_name}!\n\n"
                    f"{user_link}\n\n"
                    f"üéâ –í–∞—à AI-–∫–ª–æ–Ω –∂–¥–µ—Ç –æ–±—â–µ–Ω–∏—è!"
                )
                
        except Exception as e:
            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–∫–∏:\n{str(e)}\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∑–∞–Ω–æ–≤–æ /train_ai"
            )

    async def status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è"""
        user_id = str(update.effective_user.id)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
        data_file = f"user_data/{user_id}/training_data.json"
        has_data = os.path.exists(data_file)
        data_count = 0
        if has_data:
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                data_count = len(data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
        model_path = f"trained_models/user_{user_id}"
        has_model = os.path.exists(model_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏
        share_service = self.get_share_service()
        user_links = []
        for token, info in share_service.get_all_links().items():
            if info.get('user_id') == user_id:
                user_links.append(f"http://localhost:8001/clone/{token}/web")
        
        status_text = (
            f"üìä –°—Ç–∞—Ç—É—Å –≤–∞—à–µ–≥–æ AI-–∫–ª–æ–Ω–∞:\n\n"
            f"üìù –î–∞–Ω–Ω—ã–µ: {'‚úÖ' if has_data else '‚ùå'}\n"
            f"   ‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π: {data_count}\n\n"
            f"üß† –ú–æ–¥–µ–ª—å: {'‚úÖ' if has_model else '‚ùå'}\n"
            f"   ‚Ä¢ –û—Ç–∫—Ä—ã—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n\n"
            f"üîó –°—Å—ã–ª–∫–∏: {len(user_links)} –∞–∫—Ç–∏–≤–Ω—ã—Ö\n"
        )
        
        if user_links:
            status_text += f"\nüåê –í–∞—à–∏ —Å—Å—ã–ª–∫–∏:\n" + "\n".join(user_links)
        
        if not has_data:
            status_text += "\nüéØ –î–µ–π—Å—Ç–≤–∏–µ: /collect_data - —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"
        elif not has_model:
            status_text += "\nüéØ –î–µ–π—Å—Ç–≤–∏–µ: /train_ai - –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å (5-15 –º–∏–Ω)"
        else:
            status_text += "\nüéØ –î–µ–π—Å—Ç–≤–∏–µ: /get_link - –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É"
        
        await update.message.reply_text(status_text)

    def get_share_service(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Å—ã–ª–æ–∫"""
        try:
            from clone_server import share_service
            return share_service
        except ImportError:
            # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            class SimpleShareService:
                def __init__(self):
                    self.links = {}
                
                def generate_share_link(self, user_id, clone_name):
                    import uuid
                    token = str(uuid.uuid4())
                    self.links[token] = {
                        'user_id': user_id,
                        'name': clone_name,
                        'active': True
                    }
                    return token
                
                def get_all_links(self):
                    return {k: v for k, v in self.links.items() if v.get('active', True)}
            
            return SimpleShareService()

    async def error_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫"""
        logger.error(f"–û—à–∏–±–∫–∞: {context.error}")
        
        if update and update.effective_message:
            await update.effective_message.reply_text(
                "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É."
            )

# –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞
master_bot = MasterBot()

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await master_bot.start_command(update, context)

async def collect_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await master_bot.collect_data_command(update, context)

async def train_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await master_bot.train_ai_command(update, context)

async def get_link(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await master_bot.get_link_command(update, context)

async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await master_bot.status_command(update, context)

def main():
    if not master_bot.bot_token:
        print("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
        return
    
    try:
        application = Application.builder().token(master_bot.bot_token).build()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        application.add_handler(CommandHandler("start", start))
        application.add_handler(CommandHandler("collect_data", collect_data))
        application.add_handler(CommandHandler("train_ai", train_ai))
        application.add_handler(CommandHandler("get_link", get_link))
        application.add_handler(CommandHandler("status", status))
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
        application.add_error_handler(master_bot.error_handler)
        
        print("ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º Open AI Master Bot...")
        print("üß† –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª—è—Ö")
        print("‚ö° –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞ 5-15 –º–∏–Ω—É—Ç") 
        print("üåê –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
        print("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –ù–∞–ø–∏—à–∏—Ç–µ /start –≤ Telegram")
        
        application.run_polling()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞: {e}")

if __name__ == "__main__":
    main()