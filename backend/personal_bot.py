import os
import logging
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

load_dotenv()

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

class PersonalStyleBot:
    def __init__(self):
        self.bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞—à—É –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        try:
            self.tokenizer = AutoTokenizer.from_pretrained("./my_style_model")
            self.model = AutoModelForCausalLM.from_pretrained("./my_style_model")
            self.personal_style = True
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –≤–∞—à–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å!")
        except:
            self.personal_style = False
            print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")
    
    def generate_personal_response(self, message):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –≤–∞—à–∏–º —Å—Ç–∏–ª–µ–º"""
        prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message}\n–¢—ã:"
        
        inputs = self.tokenizer.encode(prompt, return_tensors="pt")
        
        with torch.no_grad():
            outputs = self.model.generate(
                inputs,
                max_length=150,
                num_return_sequences=1,
                temperature=0.7,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
        if "–¢—ã:" in response:
            return response.split("–¢—ã:")[-1].strip()
        return response

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ —Å—Ç–∏–ª–µ –æ–±—â–µ–Ω–∏—è –º–æ–µ–≥–æ —Å–æ–∑–¥–∞—Ç–µ–ª—è. "
        "–ü–æ–≥–æ–≤–æ—Ä–∏ —Å–æ –º–Ω–æ–π –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –æ–Ω!"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    bot = context.bot_data['personal_bot']
    user_message = update.message.text
    
    if bot.personal_style:
        response = bot.generate_personal_response(user_message)
    else:
        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –µ—â—ë –Ω–µ –≥–æ—Ç–æ–≤–∞"
    
    await update.message.reply_text(response)

def main():
    bot = PersonalStyleBot()
    
    application = Application.builder().token(bot.bot_token).build()
    application.bot_data['personal_bot'] = bot
    
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    print("ü§ñ –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –±–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    application.run_polling()

if __name__ == "__main__":
    main()