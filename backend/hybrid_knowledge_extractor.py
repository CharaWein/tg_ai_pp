# hybrid_knowledge_extractor.py
import os
import json
import logging
import re
from typing import List, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)

class HybridKnowledgeExtractor:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.raw_data_path = f"user_data/{user_id}/training_data.json"
        self.knowledge_path = f"user_data/{user_id}/knowledge_base.json"

    def extract_and_save_knowledge(self) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —Å –ø–æ–º–æ—â—å—é —à–∞–±–ª–æ–Ω–æ–≤"""
        try:
            if not os.path.exists(self.raw_data_path):
                logger.warning(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.raw_data_path}")
                return False
            
            with open(self.raw_data_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            # –ë–µ—Ä–µ–º –í–°–ï —Å–æ–æ–±—â–µ–Ω–∏—è
            all_messages = [msg.get('text', '') for msg in raw_data if msg.get('text')]
            
            if not all_messages:
                logger.warning("‚ùå –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π")
                return False
            
            logger.info(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π")
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
            knowledge = {
                "personal_info": self.extract_personal_info(all_messages),
                "interests": self.extract_interests(" ".join(all_messages)),
                "habits": self.extract_habits(" ".join(all_messages)),
                "friends": self.extract_friends(all_messages),
                "work_education": self.extract_work_education(all_messages),
                "all_messages": all_messages[:200],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è real-time –ø–æ–∏—Å–∫–∞
                "extraction_date": datetime.now().isoformat(),
                "source_messages": len(all_messages),
                "extraction_method": "enhanced_pattern_matching"
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            os.makedirs(os.path.dirname(self.knowledge_path), exist_ok=True)
            with open(self.knowledge_path, 'w', encoding='utf-8') as f:
                json.dump(knowledge, f, ensure_ascii=False, indent=2)
            
            logger.info("‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è real-time –ø–æ–∏—Å–∫–∞")
            logger.info(f"üìù –ò–∑–≤–ª–µ—á–µ–Ω–æ: {len(knowledge['personal_info'])} —Ñ–∞–∫—Ç–æ–≤, {len(knowledge['interests'])} –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π: {e}")
            return False

    def extract_personal_info(self, messages: List[str]) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é —à–∞–±–ª–æ–Ω–æ–≤"""
        info = {}
        all_text = " ".join(messages).lower()
        
        # –ò–º—è - —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        name_patterns = [
            r'–º–µ–Ω—è –∑–æ–≤—É—Ç\s+([–ê-–Ø][–∞-—è]{2,})',
            r'–º–æ–µ –∏–º—è\s+([–ê-–Ø][–∞-—è]{2,})',
            r'—è\s+([–ê-–Ø][–∞-—è]{2,})',
            r'–∑–æ–≤–∏—Ç–µ –º–µ–Ω—è\s+([–ê-–Ø][–∞-—è]{2,})'
        ]
        
        for msg in messages:
            for pattern in name_patterns:
                match = re.search(pattern, msg, re.IGNORECASE)
                if match:
                    name = match.group(1)
                    common_names = ['–∞–Ω–¥—Ä–µ–π', '–∞–ª–µ–∫—Å–µ–π', '—Å–µ—Ä–≥–µ–π', '–¥–º–∏—Ç—Ä–∏–π', '–∏–≤–∞–Ω', '–º–∞–∫—Å–∏–º', '–∞—Ä—Ç–µ–º', '–≤–ª–∞–¥–∏–º–∏—Ä']
                    if any(common_name in name.lower() for common_name in common_names):
                        info["name"] = name
                        break
            if "name" in info:
                break
        
        # –í–æ–∑—Ä–∞—Å—Ç
        age_patterns = [
            r'–º–Ω–µ\s+(\d{1,2})\s+–ª–µ—Ç',
            r'–≤–æ–∑—Ä–∞—Å—Ç\s+(\d{1,2})',
            r'(\d{1,2})\s+–≥–æ–¥'
        ]
        
        for pattern in age_patterns:
            match = re.search(pattern, all_text)
            if match:
                info["age"] = match.group(1)
                break
        
        # –ì–æ—Ä–æ–¥
        city_patterns = [
            r'–∂–∏–≤—É –≤\s+([–ê-–Ø][–∞-—è]+)',
            r'–≥–æ—Ä–æ–¥\s+([–ê-–Ø][–∞-—è]+)',
            r'–∏–∑\s+([–ê-–Ø][–∞-—è]+)',
            r'–≤\s+([–ê-–Ø][–∞-—è]+)\s+–∂–∏–≤—É'
        ]
        
        for pattern in city_patterns:
            match = re.search(pattern, all_text)
            if match:
                info["city"] = match.group(1)
                break
        
        # –†–∞–±–æ—Ç–∞
        work_patterns = [
            r'—Ä–∞–±–æ—Ç–∞—é\s+([^.,!?]+)',
            r'–∑–∞–Ω–∏–º–∞—é—Å—å\s+([^.,!?]+)',
            r'–ø—Ä–æ—Ñ–µ—Å—Å–∏—è\s+([^.,!?]+)'
        ]
        
        for pattern in work_patterns:
            match = re.search(pattern, all_text, re.IGNORECASE)
            if match:
                info["work"] = match.group(1).strip()
                break
        
        return info

    def extract_interests(self, all_text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        interests = []
        interest_keywords = {
            '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ': ['python', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–∫–æ–¥', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '–∞–ª–≥–æ—Ä–∏—Ç–º'],
            '–∏–≥—Ä—ã': ['–∏–≥—Ä', '–≥–µ–π–º', 'steam', '–∫–æ–Ω—Å–æ–ª—å', '–ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ'],
            '–º—É–∑—ã–∫–∞': ['–º—É–∑—ã–∫', '–ø–µ—Å–Ω', '–∞–ª—å–±–æ–º', '–∫–æ–Ω—Ü–µ—Ä—Ç', '–≥–∏—Ç–∞—Ä'],
            '—Å–ø–æ—Ä—Ç': ['—Å–ø–æ—Ä—Ç', '—Ñ—É—Ç–±–æ–ª', '—Ö–æ–∫–∫–µ–π', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫', '–±–µ–≥'],
            '–∫–∏–Ω–æ': ['—Ñ–∏–ª—å–º', '–∫–∏–Ω–æ', '—Å–µ—Ä–∏–∞–ª', '–∞–∫—Ç–µ—Ä', '—Ä–µ–∂–∏—Å—Å–µ—Ä'],
            '–∫–Ω–∏–≥–∏': ['–∫–Ω–∏–≥', '—á—Ç–µ–Ω–∏–µ', '–∞–≤—Ç–æ—Ä', '—Ä–æ–º–∞–Ω', '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä'],
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏', '–≥–∞–¥–∂–µ—Ç', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω', '–∫–æ–º–ø—å—é—Ç–µ—Ä', 'ai'],
            '–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è': ['–ø—É—Ç–µ—à–µ—Å—Ç–≤', '–æ—Ç–ø—É—Å–∫', '–æ—Ç–¥—ã—Ö', '—Å—Ç—Ä–∞–Ω—ã', '—Ç—É—Ä–∏–∑–º'],
            '–µ–¥–∞': ['–µ–¥–∞', '–∫—É–ª–∏–Ω–∞—Ä', '—Ä–µ—Ü–µ–ø—Ç', '–≥–æ—Ç–æ–≤–∫–∞', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω']
        }
        
        for interest, keywords in interest_keywords.items():
            if any(keyword in all_text for keyword in keywords):
                interests.append(interest)
        
        return interests[:8]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

    def extract_habits(self, all_text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–≤—ã—á–µ–∫"""
        habits = []
        habit_indicators = {
            '—É—Ç—Ä–æ': ['—É—Ç—Ä–æ–º', '–ø—Ä–æ—Å—ã–ø–∞—é—Å—å', '–∑–∞–≤—Ç—Ä–∞–∫'],
            '–∫–æ—Ñ–µ': ['–∫–æ—Ñ–µ', '—ç—Å–ø—Ä–µ—Å—Å–æ', '–∫–∞–ø—É—á–∏–Ω–æ'],
            '—Å–ø–æ—Ä—Ç': ['—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞', '–∑–∞–ª', '–±–µ–≥–∞—é', '–π–æ–≥'],
            '—á—Ç–µ–Ω–∏–µ': ['—á–∏—Ç–∞—é', '–∫–Ω–∏–≥–∞', '—Å—Ç–∞—Ç—å—è'],
            '–ø—Ä–æ–≥—É–ª–∫–∏': ['–≥—É–ª—è—é', '–ø—Ä–æ–≥—É–ª–∫–∞', '–ø–∞—Ä–∫']
        }
        
        for habit, indicators in habit_indicators.items():
            if any(indicator in all_text for indicator in indicators):
                habits.append(habit)
        
        return habits

    def extract_friends(self, messages: List[str]) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥—Ä—É–∑—å—è—Ö"""
        friends = {}
        
        for msg in messages:
            # –ü–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–º–µ–Ω –¥—Ä—É–∑–µ–π
            friend_matches = re.findall(r'(?:–¥—Ä—É–≥|–ø–æ–¥—Ä—É–≥|–∑–Ω–∞–∫–æ–º—ã–π)\s+([–ê-–Ø][–∞-—è]{2,})', msg, re.IGNORECASE)
            for friend in friend_matches:
                if friend.lower() not in ['–º–µ–Ω—è', '—Ç–µ–±—è', '—Å–µ–±—è']:  # –ò—Å–∫–ª—é—á–∞–µ–º –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è
                    friends[friend] = "–¥—Ä—É–≥"
        
        return friends

    def extract_work_education(self, messages: List[str]) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–±–æ—Ç–µ –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏"""
        work_edu = {}
        all_text = " ".join(messages).lower()
        
        # –†–∞–±–æ—Ç–∞
        work_patterns = {
            '—Ä–∞–±–æ—Ç–∞': ['—Ä–∞–±–æ—Ç–∞—é', '—Ä–∞–±–æ—Ç–∞', '–ø—Ä–æ—Ñ–µ—Å—Å–∏—è', '–¥–æ–ª–∂–Ω–æ—Å—Ç—å'],
            '—É—á–µ–±–∞': ['—É—á—É—Å—å', '—É–Ω–∏–≤–µ—Ä', '–∏–Ω—Å—Ç–∏—Ç—É—Ç', '—Å—Ç—É–¥–µ–Ω—Ç', '–∫—É—Ä—Å']
        }
        
        for key, patterns in work_patterns.items():
            if any(pattern in all_text for pattern in patterns):
                work_edu[key] = "–µ—Å—Ç—å"
        
        return work_edu

# –°–¢–ê–†–´–ô –ö–õ–ê–°–° - –û–°–¢–ê–í–õ–Ø–ï–ú –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
class SmartKnowledgeExtractor:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.raw_data_path = f"user_data/{user_id}/training_data.json"
        self.knowledge_path = f"user_data/{user_id}/knowledge_base.json"
        
    def extract_and_save_knowledge(self) -> bool:
        """–°–æ–≤–º–µ—Å—Ç–∏–º—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞"""
        try:
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {self.user_id}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
            extractor = HybridKnowledgeExtractor(self.user_id)
            success = extractor.extract_and_save_knowledge()
            
            if success:
                logger.info("‚úÖ –ó–Ω–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã")
                return True
            else:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∑–Ω–∞–Ω–∏—è")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π: {e}")
            return False

# –ù–£–ñ–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ò–ú–ü–û–†–¢–ê
def create_hybrid_knowledge_base(user_id: str) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —à–∞–±–ª–æ–Ω–æ–≤"""
    extractor = HybridKnowledgeExtractor(user_id)
    
    if extractor.extract_and_save_knowledge():
        knowledge_path = f"user_data/{user_id}/knowledge_base.json"
        if os.path.exists(knowledge_path):
            try:
                with open(knowledge_path, 'r', encoding='utf-8') as f:
                    knowledge = json.load(f)
                    logger.info(f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–∞: {len(knowledge.get('personal_info', {}))} —Ñ–∞–∫—Ç–æ–≤, {len(knowledge.get('interests', []))} –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤")
                    return knowledge
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
    
    # Fallback –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
    fallback_knowledge = {
        "personal_info": {},
        "interests": [],
        "habits": [],
        "friends": {},
        "work_education": {},
        "all_messages": [],
        "extraction_date": datetime.now().isoformat(),
        "extraction_method": "fallback_pattern_matching"
    }
    
    logger.warning("‚ö†Ô∏è –°–æ–∑–¥–∞–Ω–∞ fallback –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")
    return fallback_knowledge

def extract_knowledge(user_id: str) -> bool:
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    return create_hybrid_knowledge_base(user_id) is not None

# –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ü–û–õ–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
class KnowledgeExtractor:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.raw_data_path = f"user_data/{user_id}/training_data.json"
        self.knowledge_path = f"user_data/{user_id}/knowledge_base.json"
        
    def extract_and_save_knowledge(self) -> bool:
        """–°–æ–≤–º–µ—Å—Ç–∏–º—ã–π –º–µ—Ç–æ–¥ –¥–ª—è clone_server.py"""
        return create_hybrid_knowledge_base(self.user_id) is not None

# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏
__all__ = [
    'HybridKnowledgeExtractor',
    'SmartKnowledgeExtractor', 
    'KnowledgeExtractor',
    'create_hybrid_knowledge_base',
    'extract_knowledge'
]